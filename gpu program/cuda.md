# cuda编程

总体和c编程差不多，不过由于硬件结构和执行方式的不同和传统的编程有些需要注意的地方

### cuda gpu抽象结构

GPU Schedule => SM => Grid => Block => Warp => Thread
SM按block为单元执行任务，是硬件资源的实际承载者
其中Grid是一次任务的单元
Block是一次调度的单元
Warp是最基础的运算结构
Thread是最小的运行单元


### 总体运行方法

1. 数据从host复制到device
2. device执行算子
3. 从device复制执行结果到host

### 编码需注意的点

1.  sm占有率
sm占有率受设备和任务三个指标影响，寄存器数量/共享内存/线程数量。最终目的是让每次sm调度的时候运行的block的线程数量正好能100%占用所有的线程
以rtx3080为例， 其中 寄存器数量为65536 线程数量为1536 共享内存大小为100k。 如果一个sm要运行两个block，并且sm占有率达到100%， 那么线程数量设置为768， 共享内存不超过50kib，寄存器数量不超过42.

2.  共享内存使用
同一个block中所有线程共享使用相同的共享内存，共享内存会极大提升运算效率， 但是如果多个线程同时访问共享内存的相同位置会串行化导致效率下降。降低的方法：
    * 对于多个线程访问共享内存的同一个bank，尽量保证线程访问的数据位置在不同的bank上，避免不同线程同时访问同一个bank的不同数据。
    * 使用线程束（warp）级别的协作，即在一个线程束中的线程尽量访问不同的bank，避免线程束内的线程同时访问同一个bank的不同数据。
    * 调整共享内存的分配方式，使得不同线程访问的数据位置之间没有冲突。
    * 使用合适的内存访问模式，例如按照线程的访问模式重新组织数据，以最小化银行冲突。

3.  提升缓存命中率
设置合适的线程步长，由于线程是并行计算的，当线程同时访问数据的时候，确保这些数据在内存中都是连续的，这样受益于内存合并以及L2命中率提升，效率会更高。

4.  gpu特有的加速指令
和cp是simd类似， gpu也有一些特殊的指令可以加速一些操作(__byte_perm__ eg)。

5. 增加内存带宽利用率

在2，3点中，尽量保证一次每次读区的数据都能够使用到，有利于充分利用带宽。
